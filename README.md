This report is on using machine learning to classify neutrino events, specifically focusing on data from the NOvA experiment. This was coursework for the [UCL PHAS0056 module]([url](https://www.ucl.ac.uk/module-catalogue/modules/practical-machine-learning-for-physicists-PHAS0056)). Here’s a summary of its contents:

- **Introduction**: The report begins with an overview of neutrinos and their significance in physics. It discusses the motivation for classifying neutrino events, particularly in the context of neutrino oscillations, which are changes in neutrino flavour as they travel through matter.

- **Machine Learning Application**: The use of machine learning techniques is justified due to the large, noisy, and complex nature of the data. The report reviews existing literature and outlines the plan to create a classifier for neutrino events.

- **Data Processing**: Details on how the data was processed are provided, including normalisation techniques, data splitting, and the handling of imbalanced datasets.

- **Algorithms Used**: The report describes the architecture of the neural networks used, including the Psihas network and a custom νµ-classifier. Discussions include various layers, activation functions, and optimisation techniques used to enhance the model's performance.

- **Results**: The results section presents the performance metrics of the implemented models, including accuracy, loss, and confusion matrices. Various approaches to improving the model, such as adding more layers, introducing noise, and dropout regularisation, are analyzed.

- **Extensions**: The report explores extending the classifier to predict the final state and energy of neutrino interactions. The challenges and results of these extensions are discussed.

- **Metadata Analysis**: The impact of different data characteristics on the classifier's performance is analyzed, including the interaction type and energy levels of leptons and neutrinos.

- **Discussion and Future Work**: The report concludes with an evaluation of the methods used, highlighting the limitations and proposing future improvements, such as better data preparation and more efficient neural network architectures.

This summary covers the main points, including the technical approaches and the outcomes of the experiments conducted in the report.







